# Chinkara 7B

_Chinkara_ is a Large Language Model trained on [timdettmers/openassistant-guanaco](https://huggingface.co/datasets/timdettmers/openassistant-guanaco) dataset based on Meta's brand new LLaMa-2 with 7 billion parameters using QLoRa Technique, optimized for small consumer size GPUs. 

## Inference Notebooks 

| Model | Notebook | Description |
|:-----:|:--------:|:------------:|
|[chinkara-7b](https://huggingdace.com/MaralGPT/chinkara-7b) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/prp-e/chinkara/blob/main/inference-7b.ipynb) | This is the smallest model of the family, trained on LLaMa-2 7B |

## Inference Guide

_NOTE: This part is for the time you want to load and infere the model on your local machine. You still need 8GB of VRAM on your GPU. The recommended GPU is at least a 2080!_

### Installing libraries

### Loading the model 

### Setting the model up

### Prompt and inference